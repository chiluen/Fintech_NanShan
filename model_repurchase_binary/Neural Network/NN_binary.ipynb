{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料前處理-全轉成數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiluen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/chiluen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/chiluen/.local/lib/python3.6/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('repurchase_info.csv')\n",
    "\n",
    "#做出ICD_10\n",
    "ICD_10 = []\n",
    "for i in range(df.shape[0]):\n",
    "    ICD_10.append(ord(df['illness_code'][i][0]) - 65) #ord('A') = 65\n",
    "df['ICD_10'] = ICD_10\n",
    "\n",
    "#cleaning\n",
    "#client income有很多0, 不知道是否有問題\n",
    "df = df.drop(['REPURCHASE','INSURED_RK','Policy_RK', 'ICD10_Code_Type', 'CUST_RK','BundleSubtype2', 'illness_code', 'illness_desc', 'DiagnosisCode_DESC', 'claim_settle_dt','POLICY_HOLDER_RK'], axis = 1)\n",
    "\n",
    "#wealth_level\n",
    "dic = {'W1':0, 'W2':1, 'W3':2,'W4':3,'W5':4,'W6':5,'W7':6}\n",
    "for i in range(df.shape[0]):\n",
    "    df['WEALTH_LEVEL'][i] = dic[df['WEALTH_LEVEL'][i]]\n",
    "    \n",
    "#stick_level2\n",
    "dic = {'S01':0, 'S02':1,'S03':2,'S04':3,'S05':4,'S06':5,'S07':6,'S08':7,'S09':8,'S10':9}\n",
    "for i in range(df.shape[0]):\n",
    "    df['stick_level2'][i] = dic[df['stick_level2'][i]]\n",
    "\n",
    "#cust_group2\n",
    "dic = {'G0':0, 'G1':1,'G2':2,'G3':3,'G4':4}\n",
    "for i in range(df.shape[0]):\n",
    "    df['cust_group2'][i] = dic[df['cust_group2'][i]]\n",
    "    \n",
    "df.to_csv('repurchase_numeric.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料前處理-轉成dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('repurchase_info.csv')\n",
    "\n",
    "ICD_10 = []\n",
    "for i in range(df.shape[0]):\n",
    "    ICD_10.append(df['illness_code'][i][0]) \n",
    "df['ICD_10'] = ICD_10\n",
    "\n",
    "#cleaning\n",
    "#client income有很多0, 不知道是否有問題\n",
    "df = df.drop(['REPURCHASE','INSURED_RK','Policy_RK', 'ICD10_Code_Type', 'CUST_RK','BundleSubtype2', 'illness_code', 'illness_desc', 'DiagnosisCode_DESC', 'claim_settle_dt','POLICY_HOLDER_RK'], axis = 1)\n",
    "\n",
    "#做排序，依照：數值，binary class， multiple class，並且把multiple class做成dummy variable\n",
    "df = df[['REIMBURSED_YR_TW', 'ternure_m', 'recency_m','CLIENT_INCOME', 'AGE', 'SIN', 'SIN_his', 'REG',\n",
    "       'REG_his', 'ILP', 'ILP_his', 'AHa', 'AHa_his', 'AHb', 'AHb_his', 'AHc',\n",
    "       'AHc_his', 'AHd', 'AHd_his', 'VIP','DIGI_FLG', 'TOPCARD', 'GENDER', 'WEALTH_LEVEL','stick_level2','cust_group2','ICD_10']]\n",
    "\n",
    "dum_list = ['WEALTH_LEVEL','stick_level2','cust_group2','ICD_10']\n",
    "for i in dum_list:\n",
    "    dummies = pd.get_dummies(df[i])\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df = df.drop([i], axis = 1)\n",
    "    \n",
    "df.to_csv('repurchase_dummies.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training code - dummies edition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## df.shape = (95408, 73)\n",
    "temp = pd.read_csv('repurchase_info.csv')\n",
    "df = pd.read_csv('repurchase_dummies.csv')\n",
    "ans = np.array((temp['REPURCHASE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REIMBURSED_YR_TW</th>\n",
       "      <th>ternure_m</th>\n",
       "      <th>recency_m</th>\n",
       "      <th>CLIENT_INCOME</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SIN</th>\n",
       "      <th>SIN_his</th>\n",
       "      <th>REG</th>\n",
       "      <th>REG_his</th>\n",
       "      <th>ILP</th>\n",
       "      <th>...</th>\n",
       "      <th>O</th>\n",
       "      <th>Q</th>\n",
       "      <th>R</th>\n",
       "      <th>S</th>\n",
       "      <th>T</th>\n",
       "      <th>V</th>\n",
       "      <th>W</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28046.55</td>\n",
       "      <td>200</td>\n",
       "      <td>18</td>\n",
       "      <td>475000</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>871.50</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>2850000</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2593.50</td>\n",
       "      <td>282</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16537.50</td>\n",
       "      <td>490</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71400.00</td>\n",
       "      <td>191</td>\n",
       "      <td>119</td>\n",
       "      <td>475000</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95403</th>\n",
       "      <td>472500.00</td>\n",
       "      <td>343</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95404</th>\n",
       "      <td>4389.00</td>\n",
       "      <td>321</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95405</th>\n",
       "      <td>31133.55</td>\n",
       "      <td>263</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95406</th>\n",
       "      <td>17002.65</td>\n",
       "      <td>317</td>\n",
       "      <td>282</td>\n",
       "      <td>1425000</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95407</th>\n",
       "      <td>16825.20</td>\n",
       "      <td>297</td>\n",
       "      <td>68</td>\n",
       "      <td>760000</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95408 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       REIMBURSED_YR_TW  ternure_m  recency_m  CLIENT_INCOME  AGE  SIN  \\\n",
       "0              28046.55        200         18         475000   76    1   \n",
       "1                871.50         70         70        2850000   71    0   \n",
       "2               2593.50        282        269              0   69    0   \n",
       "3              16537.50        490        237              0   73    0   \n",
       "4              71400.00        191        119         475000   67    0   \n",
       "...                 ...        ...        ...            ...  ...  ...   \n",
       "95403         472500.00        343        120              0   57    0   \n",
       "95404           4389.00        321        201              0   53    0   \n",
       "95405          31133.55        263        240              0   54    0   \n",
       "95406          17002.65        317        282        1425000   56    0   \n",
       "95407          16825.20        297         68         760000   59    0   \n",
       "\n",
       "       SIN_his  REG  REG_his  ILP  ...  O  Q  R  S  T  V  W  X  Y  Z  \n",
       "0            1    1        1    0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "1            0    0        0    0  ...  0  0  0  0  0  1  0  0  0  0  \n",
       "2            0    0        1    0  ...  0  0  0  0  0  1  0  0  0  0  \n",
       "3            0    1        1    0  ...  0  0  0  0  0  0  0  0  1  0  \n",
       "4            0    0        0    1  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "...        ...  ...      ...  ...  ... .. .. .. .. .. .. .. .. .. ..  \n",
       "95403        0    1        1    0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "95404        0    1        1    0  ...  0  0  0  0  0  1  0  0  0  0  \n",
       "95405        0    0        0    0  ...  0  0  0  0  0  1  0  0  0  0  \n",
       "95406        0    1        1    0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "95407        0    1        1    0  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[95408 rows x 69 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##normalization\n",
    "numeric_list = ['REIMBURSED_YR_TW', 'ternure_m', 'recency_m', 'CLIENT_INCOME', 'AGE']\n",
    "for i in numeric_list:\n",
    "    df[i] = (df[i] - df[i].mean())/df[i].std()\n",
    "\n",
    "#PCA\n",
    "#pca = PCA(n_components=30)\n",
    "#df = pca.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_dataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = torch.LongTensor(y)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(df), ans, test_size=0.2, random_state=0)\n",
    "repurchase_dataset = build_dataset(X_train, y_train)\n",
    "repurchase_dataloader = DataLoader(\n",
    "    dataset = repurchase_dataset,\n",
    "    batch_size = 100,\n",
    "    shuffle = True,\n",
    "    num_workers = 2\n",
    ")\n",
    "valid_dataset = build_dataset(X_test, y_test)\n",
    "valid_dataloader = DataLoader(\n",
    "    dataset = valid_dataset,\n",
    "    batch_size = 100,\n",
    "    shuffle = False,\n",
    "    num_workers = 2\n",
    ")\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self, dimension):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dimension, 20),\n",
    "            nn.BatchNorm1d(20),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(20,10),\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(10,2),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chiluen/.local/lib/python3.6/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | train_acc: 0.841967 train_loss: 0.004790 | valid_acc: 0.895137 valid_loss: 0.004195\n",
      "Epoch: 02 | train_acc: 0.897466 train_loss: 0.004163 | valid_acc: 0.895661 valid_loss: 0.004170\n",
      "Epoch: 03 | train_acc: 0.897545 train_loss: 0.004149 | valid_acc: 0.894822 valid_loss: 0.004171\n",
      "Epoch: 04 | train_acc: 0.897650 train_loss: 0.004144 | valid_acc: 0.895504 valid_loss: 0.004162\n",
      "Epoch: 05 | train_acc: 0.897754 train_loss: 0.004140 | valid_acc: 0.895346 valid_loss: 0.004163\n",
      "Epoch: 06 | train_acc: 0.898580 train_loss: 0.004137 | valid_acc: 0.895084 valid_loss: 0.004164\n",
      "Epoch: 07 | train_acc: 0.898724 train_loss: 0.004135 | valid_acc: 0.894665 valid_loss: 0.004161\n",
      "Epoch: 08 | train_acc: 0.898868 train_loss: 0.004133 | valid_acc: 0.895346 valid_loss: 0.004165\n",
      "Epoch: 09 | train_acc: 0.898881 train_loss: 0.004131 | valid_acc: 0.895189 valid_loss: 0.004164\n",
      "Epoch: 10 | train_acc: 0.899143 train_loss: 0.004128 | valid_acc: 0.894613 valid_loss: 0.004167\n",
      "Epoch: 11 | train_acc: 0.899523 train_loss: 0.004128 | valid_acc: 0.895346 valid_loss: 0.004162\n",
      "Epoch: 12 | train_acc: 0.899733 train_loss: 0.004126 | valid_acc: 0.895242 valid_loss: 0.004165\n",
      "Epoch: 13 | train_acc: 0.899969 train_loss: 0.004124 | valid_acc: 0.893984 valid_loss: 0.004172\n",
      "Epoch: 14 | train_acc: 0.900126 train_loss: 0.004121 | valid_acc: 0.894508 valid_loss: 0.004170\n",
      "Epoch: 15 | train_acc: 0.900545 train_loss: 0.004119 | valid_acc: 0.895451 valid_loss: 0.004162\n",
      "Epoch: 16 | train_acc: 0.900322 train_loss: 0.004121 | valid_acc: 0.895189 valid_loss: 0.004164\n",
      "Epoch: 17 | train_acc: 0.900401 train_loss: 0.004119 | valid_acc: 0.894036 valid_loss: 0.004172\n",
      "Epoch: 18 | train_acc: 0.901056 train_loss: 0.004115 | valid_acc: 0.894456 valid_loss: 0.004167\n",
      "Epoch: 19 | train_acc: 0.900977 train_loss: 0.004116 | valid_acc: 0.893879 valid_loss: 0.004172\n",
      "Epoch: 20 | train_acc: 0.901266 train_loss: 0.004113 | valid_acc: 0.894351 valid_loss: 0.004170\n",
      "Epoch: 21 | train_acc: 0.901829 train_loss: 0.004111 | valid_acc: 0.893774 valid_loss: 0.004175\n",
      "Epoch: 22 | train_acc: 0.901554 train_loss: 0.004110 | valid_acc: 0.894351 valid_loss: 0.004170\n",
      "Epoch: 23 | train_acc: 0.901672 train_loss: 0.004111 | valid_acc: 0.894718 valid_loss: 0.004166\n",
      "Epoch: 24 | train_acc: 0.901672 train_loss: 0.004109 | valid_acc: 0.894875 valid_loss: 0.004173\n",
      "Epoch: 25 | train_acc: 0.901986 train_loss: 0.004106 | valid_acc: 0.894665 valid_loss: 0.004175\n",
      "Epoch: 26 | train_acc: 0.902235 train_loss: 0.004106 | valid_acc: 0.894927 valid_loss: 0.004171\n",
      "Epoch: 27 | train_acc: 0.902052 train_loss: 0.004109 | valid_acc: 0.893669 valid_loss: 0.004180\n",
      "Epoch: 28 | train_acc: 0.902445 train_loss: 0.004105 | valid_acc: 0.894351 valid_loss: 0.004176\n",
      "Epoch: 29 | train_acc: 0.902091 train_loss: 0.004106 | valid_acc: 0.893984 valid_loss: 0.004178\n",
      "Epoch: 30 | train_acc: 0.902772 train_loss: 0.004101 | valid_acc: 0.893617 valid_loss: 0.004178\n"
     ]
    }
   ],
   "source": [
    "## base line: 0.894\n",
    "\n",
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "\n",
    "# model setting\n",
    "dimension = X_train.shape[1]\n",
    "classifier = model(dimension).cuda()\n",
    "\n",
    "# parameters\n",
    "lr = 0.001\n",
    "num_epochs = 30\n",
    "CrossEntropy = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(classifier.parameters(), lr = lr)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    valid_acc = 0\n",
    "    valid_loss = 0\n",
    "    train_counter = 0\n",
    "    valid_counter = 0\n",
    "    \n",
    "    classifier.train()\n",
    "    for i, data in enumerate(repurchase_dataloader):\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        pred = classifier(data[0].float().cuda())\n",
    "        loss = CrossEntropy(pred, data[1].cuda())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        total_train_loss.append(loss.item())\n",
    "        train_acc += np.sum(np.argmax(pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    \n",
    "    #evaluation on valid set\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(valid_dataloader):\n",
    "            pred = classifier(data[0].float().cuda())\n",
    "            loss = CrossEntropy(pred, data[1].cuda())\n",
    "            \n",
    "            total_valid_loss.append(loss.item())\n",
    "            valid_acc += np.sum(np.argmax(pred.cpu().data.numpy(), axis=1) == data[1].numpy())\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    print(\"Epoch: %02d | train_acc: %6.6f train_loss: %6.6f | valid_acc: %6.6f valid_loss: %6.6f\" % \\\n",
    "          (epoch+1, train_acc/repurchase_dataset.__len__(), train_loss/repurchase_dataset.__len__(), \\\n",
    "           valid_acc/valid_dataset.__len__(), valid_loss/valid_dataset.__len__()))\n",
    "\n",
    "model_name = \"repurchase.pkl\"\n",
    "torch.save(classifier.state_dict() , model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True repurchase number: 2058 | Predict repurchase number: 456\n"
     ]
    }
   ],
   "source": [
    "# not all model_prediction are zero\n",
    "X_test_tensor = torch.tensor(X_test).float().cuda()\n",
    "\n",
    "model_predict = classifier(X_test_tensor)\n",
    "model_predict = np.argmax(model_predict.cpu().data.numpy(), axis=1)\n",
    "print(\"True repurchase number: %d | Predict repurchase number: %d\" %(sum(y_test), sum(model_predict)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
